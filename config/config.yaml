# train|inference
mode: train
device: cuda
logging_level: INFO


model: RNN
epoches: 150
# optimizer: Adam
make_checkpoint_every_n_epoch: 5
empty_cuda_cache_every_n_epoch: False
load_checkpoint_path: models\checkpoints\rnn_adam_reducelronplateau\80_epoch.pt
embeddings_path: False #data\embeddings\rnn_adam_reducelronplateau_0.pt

amp:
  enabled: False
  scaler_init_scale: 256

optimizer:
  name: adam
  lr: 1e-6

scheduler:
  scheme: ReduceLROnPlateau
  factor: .1
  patience: 8
  cooldown: 5
  threshold: 1e-3
  eps: 1e-12

archs:
  embedding_size: 100
  RNN:
    # RNN | LSTM | GRU
    block: LSTM
    hidden_size: 512
    num_layers: 4
    block_dropout: .1
    bidirectional: False

    output_dropout: .1

dataloader:
  batch_size: 16

data:
  aneks_path:
    train: data/aneks/processed/train.json
    test: data/aneks/processed/test.json
  tokens_path: data/tokens/

save_checkpoint_path: models/checkpoints/
save_embeddings_path: data/embeddings/

