# train|inference
mode: train
device: cuda
logging_level: INFO

inference:
  temperature: .1
  model: RNN
  max_len: 100
  path: models/final/lstm512_4-57.pt

model: RNN
epoches: 150
# optimizer: Adam
make_checkpoint_every_n_epoch: 1
load_checkpoint_path: models/final/lstm512_4-57.pt
embeddings_path: False #data\embeddings\rnn_adam_reducelronplateau_0.pt

amp:
  enabled: False
  scaler_init_scale: 256

optimizer:
  name: adam
  lr: 1e-3

scheduler:
  scheme: ReduceLROnPlateau
  factor: .1
  patience: 8
  cooldown: 5
  threshold: 1e-3
  eps: 1e-12

archs:
  embedding_size: 250
  RNN:
    # RNN | LSTM | GRU
    block: LSTM
    hidden_size: 512
    num_layers: 5
    block_dropout: .2
    bidirectional: False

dataloader:
  batch_size: 64

data:
  aneks_path:
    train: data/aneks/processed/train.json
    test: data/aneks/processed/test.json
  tokenizer_path: data/tokens/tokenizer.json

save_checkpoint_path: models/checkpoints/
save_embeddings_path: data/embeddings/

