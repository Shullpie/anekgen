

# train|inference
mode: train
device: cuda
logging_level: INFO


model: RNN
epoches: 100
optimizer: Adam
make_checkpoint_every_n_epoch: False
empty_cuda_cache_every_n_epoch: 2
load_checkpoint_path: False #models\checkpoints\rnn_adam_reducelronplateau\0_epoch.pt
embeddings_path: False #data\embeddings\rnn_adam_reducelronplateau_0.pt
# cpu | cuda

amp:
  enabled: True
  scaler_init_scale: 256

optimizer:
  name: adam
  lr: 1e-4

scheduler:
  scheme: ReduceLROnPlateau
  factor: .1
  patience: 15
  cooldown: 10
  threshold: 1e-6
  eps: 1e-12

archs:
  embedding_size: 50
  RNN:
    # RNN | LSTM | GRU
    block: LSTM
    hidden_size: 256
    num_layers: 4
    block_dropout: .1

    output_dropout: .1

dataloader:
  batch_size: 16

data:
  aneks_path:
    train: data/aneks/processed/train.json
    test: data/aneks/processed/test.json
  tokens_path: data/tokens/

save_checkpoint_path: models/checkpoints/
save_embeddings_path: data/embeddings/

