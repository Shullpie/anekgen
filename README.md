# Генерация анекдотов с помощью нейросетей  

## Описание проекта  
Целью проекта было создание системы, способной генерировать анекдоты на русском языке. Работа охватывает весь цикл: от сбора корпуса и обучения моделей до создания удобного интерфейса в виде Telegram-бота и развёртывания на сервере.  

Главный интерес заключался в том, чтобы проверить разные архитектуры (RNN и GPT), сравнить обучение с нуля и дообучение готовой модели, а затем довести всё до состояния работающего сервиса.  

---

## Что было сделано  

Сначала был собран корпус текстов. С помощью **Scrapy** удалось получить около **516 тысяч анекдотов**. Данные пришлось чистить: удалять дубликаты, приводить текст к единому формату.  

После этого началась работа с моделями:  

- В качестве первой пробной архитектуры была реализована **рекуррентная сеть (LSTM)**. Она показала базовый уровень качества и помогла наладить процесс обучения.  
- Далее была написана своя упрощённая версия **GPT** на 10 слоях. Модель обучалась с нуля на собранном корпусе.  
- Отдельное направление — использование готовой модели **ruGPT от Сбера**. Её удалось адаптировать под задачу генерации анекдотов с помощью **LoRA (Low-Rank Adaptation)**. В процессе экспериментировались с рангами адаптации, разморозкой выходного слоя, планировщиками learning rate и warmup.  

Когда модели начали выдавать осмысленные результаты, было решено сделать удобный интерфейс. Для этого написан **Telegram-бот** на базе **aiogram**. Бот принимает запрос, отправляет его в выбранную модель (RNN, собственная GPT или GPT с LoRA) и возвращает результат. Чтобы генерация не блокировала работу бота, обработка запросов сделана асинхронной. Чтобы систему можно было развернуть на любом сервере, весь проект упакован в **Docker**.
---

## Как это работает  

1. Пользователь пишет боту в Telegram.  
2. Запрос передаётся в модель генерации (выбор между RNN, GPT и GPT+LoRA).  
3. Модель на основе корпуса из сотен тысяч анекдотов формирует ответ.  
4. Сгенерированный текст возвращается пользователю.  

---

## Итог  

В результате получилась законченная система, которая объединяет в себе исследовательскую часть и готовый продукт:  

- собран и обработан большой корпус текстов,  
- реализованы и обучены собственные модели (RNN и GPT),  
- дообучена предобученная GPT с помощью LoRA,  
- создан Telegram-бот для взаимодействия с пользователем,  
- всё упаковано в Docker и развёрнуто на сервере.  

Проект показывает, как можно пройти весь путь — от сырых данных до работающего сервиса — и применить современные методы обработки естественного языка к такой необычной задаче, как генерация анекдотов.  
